{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"color:red\"> -Scrapping Data From Naukri.com Website </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobRole</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>python, data analytics, tableau, data visualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Science, Data Visualization, Data Analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>data analytics, natural language processing, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>algorithms, python, modeling, data analysis, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>python, data analytics, cloud technologies, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>AWS Cloud Engineer</td>\n",
       "      <td>continuous integration, cloud security, Archit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Cloud Engineers</td>\n",
       "      <td>Computer science, Analytical skills, Performan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>Sr. Cloud Engineer - AWS</td>\n",
       "      <td>Cloud computing, Networking, Cloud, Back offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Cloud Engineer</td>\n",
       "      <td>VMware, Linux, Storage management, Disaster re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Azure Cloud Engineer</td>\n",
       "      <td>Solution design, Networking, Design review, In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1591 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      JobRole  \\\n",
       "0     Data Scientist: Artificial Intelligence   \n",
       "1                              Data Scientist   \n",
       "2                              Data Scientist   \n",
       "3                              Data Scientist   \n",
       "4     Data Scientist: Artificial Intelligence   \n",
       "...                                       ...   \n",
       "1586                       AWS Cloud Engineer   \n",
       "1587                          Cloud Engineers   \n",
       "1588                 Sr. Cloud Engineer - AWS   \n",
       "1589                           Cloud Engineer   \n",
       "1590                     Azure Cloud Engineer   \n",
       "\n",
       "                                                 Skills  \n",
       "0     python, data analytics, tableau, data visualiz...  \n",
       "1     Data Science, Data Visualization, Data Analyti...  \n",
       "2     data analytics, natural language processing, d...  \n",
       "3     algorithms, python, modeling, data analysis, d...  \n",
       "4     python, data analytics, cloud technologies, ta...  \n",
       "...                                                 ...  \n",
       "1586  continuous integration, cloud security, Archit...  \n",
       "1587  Computer science, Analytical skills, Performan...  \n",
       "1588  Cloud computing, Networking, Cloud, Back offic...  \n",
       "1589  VMware, Linux, Storage management, Disaster re...  \n",
       "1590  Solution design, Networking, Design review, In...  \n",
       "\n",
       "[1591 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver using Service and ChromeDriverManager\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "JobTitle = []\n",
    "Skills = []\n",
    "\n",
    "#############################################################################################################\n",
    "# 1. Web Scrapping Data Science \n",
    "# Loop to fetch job listings for 20 iterations\n",
    "for loop in range(1, 21):  # Looping from 1 to 20\n",
    "    # Construct the updated URL with the job identifier\n",
    "    job_url = f\"https://www.naukri.com/data-scientist-data-science-jobs-{loop}?k=data%20scientist%2C%20data%20science&nignbevent_src=jobsearchDeskGNB\"\n",
    "    \n",
    "    # Open the webpage\n",
    "    driver.get(job_url)\n",
    "\n",
    "    # Wait for a few seconds to allow the page to fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source after JavaScript has executed\n",
    "    page_content = driver.page_source\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    # Find all job listing boxes on the Web-Page\n",
    "    box = soup.find_all('div', class_=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple\")\n",
    "\n",
    "    # Loop through each job listing box to extract data\n",
    "    for i in box:\n",
    "\n",
    "        # Extracting JobTitle\n",
    "        Job = i.find('a', class_='title')\n",
    "        JobTitle.append(Job.text.strip() if Job else 'N/A')\n",
    "        \n",
    "        # Extracting Skills\n",
    "        skills_list = i.find('ul', class_='tags-gt')\n",
    "        # If skills_list is found, join the individual skills with a comma\n",
    "        if skills_list:\n",
    "            skills = [skill.text.strip() for skill in skills_list.find_all('li')]\n",
    "            Skills.append(', '.join(skills))\n",
    "        else:\n",
    "            Skills.append('N/A')\n",
    "\n",
    "# Close the driver after fetching the content\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# 2. Web Scrapping Software Engineering\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "for loop in range(1, 21):  # Looping from 1 to 20\n",
    "    # Construct the updated URL with the job identifier\n",
    "    job_url = f\"https://www.naukri.com/software-engineering-jobs-{loop}?k=software%20engineering&nignbevent_src=jobsearchDeskGNB\"\n",
    "    \n",
    "    # Open the webpage\n",
    "    driver.get(job_url)\n",
    "\n",
    "    # Wait for a few seconds to allow the page to fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source after JavaScript has executed\n",
    "    page_content = driver.page_source\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    # Find all job listing boxes on the Web-Page\n",
    "    box = soup.find_all('div', class_=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple\")\n",
    "\n",
    "    # Loop through each job listing box to extract data\n",
    "    for i in box:\n",
    "\n",
    "        # Extracting JobTitle\n",
    "        Job = i.find('a', class_='title')\n",
    "        JobTitle.append(Job.text.strip() if Job else 'N/A')\n",
    "        \n",
    "        # Extracting Skills\n",
    "        skills_list = i.find('ul', class_='tags-gt')\n",
    "        # If skills_list is found, join the individual skills with a comma\n",
    "        if skills_list:\n",
    "            skills = [skill.text.strip() for skill in skills_list.find_all('li')]\n",
    "            Skills.append(', '.join(skills))\n",
    "        else:\n",
    "            Skills.append('N/A')\n",
    "\n",
    "# Close the driver after fetching the content\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# 3. Web Scrapping Software Testing\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "for loop in range(1, 21):  # Looping from 1 to 20\n",
    "    # Construct the updated URL with the job identifier\n",
    "    job_url = f\"https://www.naukri.com/software-testing-jobs-{loop}?k=software%20testing&nignbevent_src=jobsearchDeskGNB\"\n",
    "    \n",
    "    # Open the webpage\n",
    "    driver.get(job_url)\n",
    "\n",
    "    # Wait for a few seconds to allow the page to fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source after JavaScript has executed\n",
    "    page_content = driver.page_source\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    # Find all job listing boxes on the Web-Page\n",
    "    box = soup.find_all('div', class_=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple\")\n",
    "\n",
    "    # Loop through each job listing box to extract data\n",
    "    for i in box:\n",
    "\n",
    "        # Extracting JobTitle\n",
    "        Job = i.find('a', class_='title')\n",
    "        JobTitle.append(Job.text.strip() if Job else 'N/A')\n",
    "        \n",
    "        # Extracting Skills\n",
    "        skills_list = i.find('ul', class_='tags-gt')\n",
    "        # If skills_list is found, join the individual skills with a comma\n",
    "        if skills_list:\n",
    "            skills = [skill.text.strip() for skill in skills_list.find_all('li')]\n",
    "            Skills.append(', '.join(skills))\n",
    "        else:\n",
    "            Skills.append('N/A')\n",
    "\n",
    "# Close the driver after fetching the content\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# 4. Web Scrapping Cloud Engineering\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "for loop in range(1, 21):  # Looping from 1 to 20\n",
    "    # Construct the updated URL with the job identifier\n",
    "    job_url = f\"https://www.naukri.com/cloud-engineering-jobs-{loop}?k=cloud%20engineering&nignbevent_src=jobsearchDeskGNB\"\n",
    "    \n",
    "    # Open the webpage\n",
    "    driver.get(job_url)\n",
    "\n",
    "    # Wait for a few seconds to allow the page to fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source after JavaScript has executed\n",
    "    page_content = driver.page_source\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    # Find all job listing boxes on the Web-Page\n",
    "    box = soup.find_all('div', class_=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple\")\n",
    "\n",
    "    # Loop through each job listing box to extract data\n",
    "    for i in box:\n",
    "        \n",
    "        # Extracting JobTitle\n",
    "        Job = i.find('a', class_='title')\n",
    "        JobTitle.append(Job.text.strip() if Job else 'N/A')\n",
    "        \n",
    "        # Extracting Skills\n",
    "        skills_list = i.find('ul', class_='tags-gt')\n",
    "        # If skills_list is found, join the individual skills with a comma\n",
    "        if skills_list:\n",
    "            skills = [skill.text.strip() for skill in skills_list.find_all('li')]\n",
    "            Skills.append(', '.join(skills))\n",
    "        else:\n",
    "            Skills.append('N/A')\n",
    "\n",
    "# Close the driver after fetching the content\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Create a dictionary to hold the job data\n",
    "dic = {\n",
    "    'JobRole': JobTitle,\n",
    "    'Skills': Skills\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(dic)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "### **<span style=\"color:black\"> -Converting it to CSV FIle </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to start from 1\n",
    "df.index = df.index + 1\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Data.csv', index=True)             # by default indexing starts from 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
